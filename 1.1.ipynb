{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "062ad358",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting rotational search across 360 angles...\n",
      "\n",
      "--- Matching Complete ---\n",
      "**Template size:** 186x218 pixels\n",
      "**Search Center:** (1616, 1607)\n",
      "\n",
      "## ðŸŽ‰ Highest Match Found\n",
      "**Highest Feature Match Value (Correlation Score):** **1.0000**\n",
      "**Best Match Location (Top-Left Corner):** (34, 1672)\n",
      "**Optimal Rotation Angle:** 0Â°\n",
      "**Center of Matched Feature:** (127, 1781)\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# --- 1. Load Images and Define Parameters ---\n",
    "# NOTE: Replace these placeholder images with your actual loaded image data\n",
    "# full_chip_image = cv2.imread('1.jpg', cv2.IMREAD_GRAYSCALE)\n",
    "# template_image = cv2.imread('A1_cropped_template.png', cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "# For a functional example, assume these are loaded successfully\n",
    "# We need to simulate the loading/cropping step for the template (A1.png is a crop of 1.jpg)\n",
    "# Since I cannot perform the crop for you, I'll use placeholders:\n",
    "# The main chip image '1.jpg' is 3200x3200 (based on typical microfluidic scans)\n",
    "# The template is a smaller image containing feature '12'\n",
    "\n",
    "# --- Placeholder Data (You must replace with actual loaded images) ---\n",
    "try:\n",
    "    # Attempt to load the images (will fail in this environment, but conceptually necessary)\n",
    "    full_chip_image = cv2.imread(r\"D:\\Test1\\1024_13_G.png\", cv2.IMREAD_GRAYSCALE)\n",
    "    # The actual template is a crop around the '12' feature\n",
    "    # A simple estimation based on the image: (let's assume a 400x400 crop around '12')\n",
    "    # Y-range: 1616 - 800 to 1616 - 400  => 816 to 1216 (approx)\n",
    "    # X-range: 1603 - 400 to 1603 + 0    => 1203 to 1603 (approx)\n",
    "    # We will conceptually use a loaded template:\n",
    "    template_image = cv2.imread(r\"D:\\Test1\\8temp.png\", cv2.IMREAD_GRAYSCALE) # Assuming A1.png is the template\n",
    "    \n",
    "    # Check if images are loaded successfully\n",
    "    if full_chip_image is None or template_image is None:\n",
    "        print(\"Error: Could not load images. Please ensure file paths are correct.\")\n",
    "        # Create dummy images for demonstration if loading fails\n",
    "        raise FileNotFoundError\n",
    "        \n",
    "except FileNotFoundError:\n",
    "    print(\"Using dummy data for demonstration purposes as real loading failed.\")\n",
    "    full_chip_image = np.zeros((3200, 3200), dtype=np.uint8) + 128\n",
    "    template_image = np.zeros((400, 400), dtype=np.uint8) + 150\n",
    "    \n",
    "\n",
    "# Chip Center (from your input)\n",
    "chip_center_x, chip_center_y = 1616,1607\n",
    "\n",
    "# Template properties\n",
    "tw, th = template_image.shape[::-1] # Template width and height (inverted for numpy/cv2)\n",
    "template_center = (tw // 2, th // 2)\n",
    "\n",
    "# Parameters for the search\n",
    "# Given 12 features, a 30-degree step is expected. \n",
    "# We use a 1-degree step for high precision to find the absolute best match.\n",
    "# Search range is 0 to 360 degrees.\n",
    "angle_step = 1 \n",
    "angles = np.arange(0, 360, angle_step)\n",
    "\n",
    "# Variables to store the best result\n",
    "best_match_value = -1.0 # Correlation score is between -1.0 and 1.0\n",
    "best_location = (0, 0)\n",
    "best_angle = 0\n",
    "\n",
    "# --- 2. Define Rotation Helper Function ---\n",
    "def rotate_template(img, angle, center):\n",
    "    \"\"\"Rotates the template image around its center.\"\"\"\n",
    "    M = cv2.getRotationMatrix2D(center, angle, 1.0)\n",
    "    rotated = cv2.warpAffine(img, M, (img.shape[1], img.shape[0]), \n",
    "                             flags=cv2.INTER_LINEAR, \n",
    "                             borderMode=cv2.BORDER_CONSTANT,\n",
    "                             borderValue=(0)) # Use black border\n",
    "    return rotated\n",
    "\n",
    "# --- 3. Iterative Rotation and Matching ---\n",
    "print(f\"Starting rotational search across {len(angles)} angles...\")\n",
    "\n",
    "for angle in angles:\n",
    "    # a. Rotate the template\n",
    "    rotated_template = rotate_template(template_image, angle, template_center)\n",
    "    \n",
    "    # b. Perform Template Matching (Normalized Cross-Correlation)\n",
    "    # TM_CCOEFF_NORMED is the standard for robust, normalized matching\n",
    "    result_map = cv2.matchTemplate(full_chip_image, rotated_template, cv2.TM_CCOEFF_NORMED)\n",
    "    \n",
    "    # c. Find the best match value and location for this specific rotation\n",
    "    min_val, max_val, min_loc, max_loc = cv2.minMaxLoc(result_map)\n",
    "    \n",
    "    # d. Update the global best result\n",
    "    if max_val > best_match_value:\n",
    "        best_match_value = max_val\n",
    "        best_location = max_loc\n",
    "        best_angle = angle\n",
    "\n",
    "    # Optional: Print progress every 30 degrees\n",
    "    # if angle % 30 == 0:\n",
    "    #    print(f\"Angle {angle}Â°: Max Value = {max_val:.4f}\")\n",
    "\n",
    "\n",
    "# --- 4. Final Output ---\n",
    "print(\"\\n--- Matching Complete ---\")\n",
    "print(f\"**Template size:** {tw}x{th} pixels\")\n",
    "print(f\"**Search Center:** ({chip_center_x}, {chip_center_y})\")\n",
    "\n",
    "print(\"\\n## ðŸŽ‰ Highest Match Found\")\n",
    "print(f\"**Highest Feature Match Value (Correlation Score):** **{best_match_value:.4f}**\")\n",
    "print(f\"**Best Match Location (Top-Left Corner):** {best_location}\")\n",
    "print(f\"**Optimal Rotation Angle:** {best_angle}Â°\")\n",
    "\n",
    "# Calculate the center of the best-matched feature\n",
    "center_of_match = (best_location[0] + tw // 2, best_location[1] + th // 2)\n",
    "print(f\"**Center of Matched Feature:** {center_of_match}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1e5baf8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using dummy data for visualization. Please ensure images are loaded correctly.\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# --- Re-use necessary variables from previous run ---\n",
    "# Assuming 'full_chip_image', 'template_image', 'best_location',\n",
    "# 'tw', 'th', 'best_angle', and 'template_center' are defined from the previous script run.\n",
    "\n",
    "# For demonstration, if you're running this in a new session, you'd need to re-load:\n",
    "try:\n",
    "    full_chip_image_color = cv2.imread(r\"D:\\Test1\\1024_13_G.png\",cv2.IMREAD_GRAYSCALE) # Load in color for visualization\n",
    "    template_image = cv2.imread(r\"D:\\Test1\\8temp.png\", cv2.IMREAD_GRAYSCALE)\n",
    "    if full_chip_image_color is None or template_image is None:\n",
    "        raise FileNotFoundError\n",
    "except FileNotFoundError:\n",
    "    print(\"Using dummy data for visualization. Please ensure images are loaded correctly.\")\n",
    "    full_chip_image_color = np.zeros((3200, 3200, 3), dtype=np.uint8) + 128\n",
    "    template_image = np.zeros((228, 234), dtype=np.uint8) + 150 # Match the template size from output\n",
    "\n",
    "# Dummy values for best_location and best_angle if not already set (based on your output)\n",
    "if 'best_location' not in locals():\n",
    "    best_location = (1020, 96)\n",
    "if 'best_angle' not in locals():\n",
    "    best_angle = 0\n",
    "if 'tw' not in locals() or 'th' not in locals():\n",
    "    th, tw = template_image.shape[:2] # height, width\n",
    "if 'template_center' not in locals():\n",
    "    template_center = (tw // 2, th // 2)\n",
    "\n",
    "# Ensure full_chip_image_color is indeed a color image for drawing\n",
    "if len(full_chip_image_color.shape) == 2: # If it was loaded as grayscale\n",
    "    full_chip_image_color = cv2.cvtColor(full_chip_image_color, cv2.COLOR_GRAY2BGR)\n",
    "\n",
    "# --- 1. Prepare the rotated template for drawing ---\n",
    "# We need the rotated template's dimensions to draw the correct bounding box.\n",
    "# If the optimal angle is 0, this is just the original template.\n",
    "def rotate_template_for_drawing(img, angle, center):\n",
    "    \"\"\"Rotates the template image around its center.\"\"\"\n",
    "    M = cv2.getRotationMatrix2D(center, angle, 1.0)\n",
    "    rotated = cv2.warpAffine(img, M, (img.shape[1], img.shape[0]),\n",
    "                             flags=cv2.INTER_LINEAR,\n",
    "                             borderMode=cv2.BORDER_CONSTANT,\n",
    "                             borderValue=(0)) # Use black border\n",
    "    return rotated\n",
    "\n",
    "rotated_template_for_vis = rotate_template_for_drawing(template_image, best_angle, template_center)\n",
    "# Get actual dimensions of the rotated template (can change if angle is not 0 due to padding)\n",
    "rot_h, rot_w = rotated_template_for_vis.shape[:2]\n",
    "\n",
    "\n",
    "# --- 2. Draw the rectangle on the main image ---\n",
    "# Define the top-left and bottom-right corners of the bounding box\n",
    "top_left = best_location\n",
    "bottom_right = (top_left[0] + rot_w, top_left[1] + rot_h)\n",
    "\n",
    "# Draw a rectangle on the image\n",
    "# Parameters: image, top-left corner, bottom-right corner, color (BGR), thickness\n",
    "cv2.rectangle(full_chip_image_color, top_left, bottom_right, (0, 255, 0), 5) # Green rectangle, 5 pixels thick\n",
    "\n",
    "# Optionally, draw a circle at the center of the matched feature\n",
    "center_of_match = (best_location[0] + tw // 2, best_location[1] + th // 2)\n",
    "cv2.circle(full_chip_image_color, center_of_match, 10, (0, 0, 255), -1) # Red circle, filled\n",
    "\n",
    "# --- 3. Display the result ---\n",
    "# It's good practice to resize for display if the image is very large\n",
    "display_image = cv2.resize(full_chip_image_color, (full_chip_image_color.shape[1] // 2, full_chip_image_color.shape[0] // 2)) # Resize to half for viewing\n",
    "\n",
    "cv2.imshow('Matched Feature on Microfluidic Chip', display_image)\n",
    "cv2.waitKey(0) # Wait indefinitely until a key is pressed\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "# --- 4. Save the result ---\n",
    "# You might want to save the annotated image\n",
    "output_filename = 'matched_feature_annotated.jpg'\n",
    "cv2.imwrite(output_filename, full_chip_image_color)\n",
    "print(f\"Annotated image saved as '{output_filename}'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32004a20",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "445b6500",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
